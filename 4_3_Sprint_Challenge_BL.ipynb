{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4-3-Sprint-Challenge_BL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.21.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blakelobato/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/4_3_Sprint_Challenge_BL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDVhulkPPRrV",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KsPBDqvPbtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "87a6906c-80f9-45b2-92b5-64ba3a86138a"
      },
      "source": [
        "# Check that we have a GPU instance of Colab\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May  4 01:42:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMSs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcqfmWjW-SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, MaxPooling1D, PReLU, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQxPVRrCW8NX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "81dfe9b1-64e0-4469-a9c3-9e3af9d1ff4a"
      },
      "source": [
        "# Concatonate test and training datasets\n",
        "allreviews = np.concatenate((X_train, X_test), axis=0)\n",
        "\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len)))) #length cuz words are integers\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result))) #normalize length of reviews in process\n",
        "\n",
        "# Print a review and it's class as stored in the dataset. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Machine readable Review\")\n",
        "print(\"  Review Text: \" + str(X_train[60])) #testing showing 60'th review \n",
        "print(\"  Review Sentiment: \" + str(y_train[60]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 2376\n",
            "Minimum review length: 2\n",
            "Mean review length: 145.96419665122906\n",
            "\n",
            "Machine readable Review\n",
            "  Review Text: [1, 53, 46, 160, 26, 14, 74, 142, 26, 39, 46, 4312, 4938, 14, 74, 957, 4835, 86, 19, 445, 18, 14, 32, 451, 18, 17, 12]\n",
            "  Review Sentiment: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aLMq-b2XF2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5d4a57f9-6752-4ff8-84cb-29968c4bfe5a"
      },
      "source": [
        "# If you want to pad the end of the sequences you can set padding='post'.\n",
        "maxlen = 200 #try to limit to 300 words cuz like 70% of reviews and shorten the rest with 1000 words or something\n",
        "#not to mention 300 words most likely gunna havce the negative shit\n",
        "#value impacts nn later on\n",
        "\n",
        "\n",
        "#pad sequences\n",
        "print('Pad Sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen) #takes sequences in and normalize them to length 300\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('x_train shape: ', X_train.shape)\n",
        "print('x_test shape: ', X_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (8982, 200)\n",
            "x_test shape:  (2246, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "a89b558d-7387-4b31-9499-76f45e837cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {}
      },
      "source": [
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(word_index.values()) + 1\n",
        "\n",
        "# TODO - your code!\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhuZdRUXQgDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9648f123-e7b3-4125-eed6-354a2fdcf2c3"
      },
      "source": [
        "#see max amount of features\n",
        "max_features"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viG1nnMxRz-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ce2346a-bb64-4ab7-d0ca-b72f55046ac2"
      },
      "source": [
        "# get number of classes to return\n",
        "numbered_classes = max(y_train) + 1\n",
        "print(numbered_classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QoaVcTGT0JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52080754-595b-44dc-e800-03c4ea6c5d8b"
      },
      "source": [
        "#batch size for the articles\n",
        "batch_size = 32\n",
        "print(batch_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUVH83ZLV4Ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f2aea64b-4395-4cc2-bb5e-f5d72c4183af"
      },
      "source": [
        "#build LSTM model\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_features, 128))\n",
        "lstm.add(LSTM(128, return_sequences=True)) #now lstm layer\n",
        "lstm.add(Dropout(0.20))\n",
        "lstm.add(LSTM(128)) #if two lstm layers need return sequences up there\n",
        "lstm.add(Dropout(0.20))\n",
        "lstm.add(Dense(numbered_classes, activation='softmax'))\n",
        "\n",
        "lstm.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "lstm.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         3965440   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 128)         131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 46)                5934      \n",
            "=================================================================\n",
            "Total params: 4,234,542\n",
            "Trainable params: 4,234,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWzqQeZhSmlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add early stopping\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOmmwHhxS-LW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "5b57cc87-7489-4905-f683-448ce63775e5"
      },
      "source": [
        "lstm_hist = lstm.fit(X_train, y_train, batch_size=batch_size, epochs=25, validation_data=(X_test, y_test), callbacks=[stop])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "281/281 [==============================] - 18s 62ms/step - loss: 0.7080 - accuracy: 0.8146 - val_loss: 1.5068 - val_accuracy: 0.6572\n",
            "Epoch 2/25\n",
            "281/281 [==============================] - 18s 62ms/step - loss: 0.6177 - accuracy: 0.8357 - val_loss: 1.4437 - val_accuracy: 0.6790\n",
            "Epoch 3/25\n",
            "281/281 [==============================] - 16s 59ms/step - loss: 0.5506 - accuracy: 0.8549 - val_loss: 1.6032 - val_accuracy: 0.6474\n",
            "Epoch 4/25\n",
            "281/281 [==============================] - 16s 59ms/step - loss: 0.5061 - accuracy: 0.8656 - val_loss: 1.4429 - val_accuracy: 0.6759\n",
            "Epoch 5/25\n",
            "281/281 [==============================] - 17s 61ms/step - loss: 0.4368 - accuracy: 0.8857 - val_loss: 1.5143 - val_accuracy: 0.6839\n",
            "Epoch 6/25\n",
            "281/281 [==============================] - 17s 59ms/step - loss: 0.4307 - accuracy: 0.8843 - val_loss: 1.5146 - val_accuracy: 0.6763\n",
            "Epoch 7/25\n",
            "281/281 [==============================] - 17s 59ms/step - loss: 0.3696 - accuracy: 0.9022 - val_loss: 1.5386 - val_accuracy: 0.6848\n",
            "Epoch 8/25\n",
            "281/281 [==============================] - 17s 59ms/step - loss: 0.3036 - accuracy: 0.9195 - val_loss: 1.6545 - val_accuracy: 0.6785\n",
            "Epoch 9/25\n",
            "281/281 [==============================] - 16s 59ms/step - loss: 0.2770 - accuracy: 0.9275 - val_loss: 1.7309 - val_accuracy: 0.6541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffupfK5SbxTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_train = 92.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOce5emBa2Bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0f9e9f88-d256-41d1-bb03-55babb77449e"
      },
      "source": [
        "score, acc = lstm.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 1s 9ms/step - loss: 1.7309 - accuracy: 0.6541\n",
            "Test score: 1.7308952808380127\n",
            "Test accuracy: 0.654051661491394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13kVn86TcxbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = acc*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyTTiUz-a73k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "adff789a-eba5-4dec-c439-e2bb3e553ac5"
      },
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lstm_hist.history['loss'])\n",
        "plt.plot(lstm_hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvaWVLlObNOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e088e46c-9be0-4f6c-9f6f-c597e9d95f41"
      },
      "source": [
        "print('We were able to get ~65% accuracy on the training data actual:', acc_train)\n",
        "print('We were able to get ~67% accuracy on the test data actual:', acc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We were able to get ~65% accuracy on the training data actual: 92.75\n",
            "We were able to get ~67% accuracy on the test data actual: 65.4051661491394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "VoKXTXQuPRre",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "- pad_sequences does exactly what it sounds like... It pads sequences to the same length. This helps the LSTM take in the same shape it expects for each entry. This transforms our numpy list of integers into a 2-D array. If they are too small they are given zeros at the end and if they are too long they are truncated.\n",
        "\n",
        "\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "- LSTM uses the forget functionality which is different than traditional Recurrent Neural Networks. This is a way to be stronger than RNNs in accuracy metrics in some cases due to the fact tht LSTM's can forget aspects that don't help promote overall success whereras RNNs are unable to do so, thus carrying values that don't push towards a maximum accuracy. LSTMs can put more emphasis on a value that it recently found to help greatly over values it has previously learned does not help as well.\n",
        "\n",
        "\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "- Text Classifcation\n",
        "- Text Generation\n",
        "- Video Classification/Image Captioning\n",
        "- Time Series Data Forecasting or Sequential data analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and [ResNet50v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2) (pre-trained) to detect which of the images with the `frog_images` subdirectory has a frog in it. Note: You will need to upload the images to Colab. \n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VIgcFzKfv-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4ebcda03-822e-45d4-fc80-6f15d34b2a81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2v30BzOkXsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread_collection\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvyFbjyLxY2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/U4S3 Challenge 3/BulkResizePhotos/*.jpg'\n",
        "#creating a collection with the available images\n",
        "X_test = imread_collection(test_images).concatenate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeazyGW4xjHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b90f9ae4-756e-43ac-f2b4-5f4d2f1af9b3"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 600, 800, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLycNsBNxjZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50V2(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTUDla5vzeFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = preprocess_input(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6nfGp4JxjXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGbGlTVaxjWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = decode_predictions(predictions) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ei-KQbVxjS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36722afa-3391-4bdb-a598-ef7c08935cd0"
      },
      "source": [
        "labels"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n02356798', 'fox_squirrel', 1.0),\n",
              "  ('n02089973', 'English_foxhound', 2.6367866e-33),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02321529', 'sea_cucumber', 0.0),\n",
              "  ('n02395406', 'hog', 0.0)],\n",
              " [('n02356798', 'fox_squirrel', 1.0),\n",
              "  ('n07613480', 'trifle', 1.4100145e-10),\n",
              "  ('n02089973', 'English_foxhound', 9.574201e-21),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n02089973', 'English_foxhound', 0.99968433),\n",
              "  ('n02356798', 'fox_squirrel', 0.00031564475),\n",
              "  ('n07613480', 'trifle', 6.2005035e-17),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0)],\n",
              " [('n02089973', 'English_foxhound', 0.9999999),\n",
              "  ('n02356798', 'fox_squirrel', 6.2639074e-08),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02321529', 'sea_cucumber', 0.0),\n",
              "  ('n02395406', 'hog', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n02356798', 'fox_squirrel', 0.9976533),\n",
              "  ('n02089973', 'English_foxhound', 0.0023467646),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02321529', 'sea_cucumber', 0.0),\n",
              "  ('n02395406', 'hog', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n02356798', 'fox_squirrel', 0.9992218),\n",
              "  ('n02089973', 'English_foxhound', 0.0007782262),\n",
              "  ('n07613480', 'trifle', 2.8559886e-17),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0)],\n",
              " [('n02089973', 'English_foxhound', 1.0),\n",
              "  ('n02356798', 'fox_squirrel', 1.5426014e-18),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02321529', 'sea_cucumber', 0.0),\n",
              "  ('n02395406', 'hog', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)],\n",
              " [('n07613480', 'trifle', 1.0),\n",
              "  ('n15075141', 'toilet_tissue', 0.0),\n",
              "  ('n02317335', 'starfish', 0.0),\n",
              "  ('n02391049', 'zebra', 0.0),\n",
              "  ('n02389026', 'sorrel', 0.0)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9a5iVH_0PJ6",
        "colab_type": "text"
      },
      "source": [
        "# Once resizing images they came as trifle, or fox_squirrel, etc. So they need to be reshaped for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0E2BqmPRrf",
        "colab_type": "text"
      },
      "source": [
        "The skimage function below will help you read in all the frog images into memory at once. You should use the preprocessing functions that come with ResnetV2 to help resize the images prior to inference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread_collection\n",
        "\n",
        "#images = imread_collection('./frog_images/*.jpg')\n",
        "images = imread_collection('/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/U4S3 Challenge 3/frog_images/*.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "8e3868e9-051c-4479-f3c3-e370fad0dfff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(type(images))\n",
        "print(type(images[0]), end=\"\\n\\n\")"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'skimage.io.collection.ImageCollection'>\n",
            "<class 'numpy.ndarray'>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRzIL-zLitTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd2c6dfc-9f8f-4828-e695-6acfb84d6dc5"
      },
      "source": [
        "images[1].shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3810, 2856, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t7mEy8Rjrqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64e2026d-11dd-4573-9dfa-fd66d6e5a7de"
      },
      "source": [
        "images[2].shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3456, 4608, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40dPvT81jpKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "760dadba-0bbf-4c5c-f4a4-ef1f71752340"
      },
      "source": [
        "images[3].shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 3335, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyS0EkwjjxpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12f6f5b7-3f7f-4be2-d3e3-c284e2c863c9"
      },
      "source": [
        "images[4].shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 3008, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXaiZoNCjxra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46e154ea-b1eb-4683-99b5-4b1971a95b29"
      },
      "source": [
        "images[5].shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2883, 4319, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6rj15YdjxwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41ed588f-f6e6-4379-efae-0030755bbc6e"
      },
      "source": [
        "images[6].shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 6000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRTdlNHfjx0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a954dbb-989f-4297-8d28-f66b3a11fe1d"
      },
      "source": [
        "images[7].shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2642, 3918, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxFC0XVyjx8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f989780-3ec1-467d-ae29-3e79cad01bda"
      },
      "source": [
        "images[8].shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3456, 5184, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-M3MDNjx7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7346c15d-4991-4e9b-be7a-91926d4e538b"
      },
      "source": [
        "images[9].shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2912, 4368, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TisSKbWmjx5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e33ef26a-ae8a-497c-8d2b-ec7188a620a7"
      },
      "source": [
        "images[10].shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4928, 3285, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zfs8LbHjx4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d3460a3-02b1-47bf-e28f-b499642106d5"
      },
      "source": [
        "images[11].shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3702, 5397, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOpG_2Rhjxy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76e35372-6101-4097-87d9-0d0e7f6fa242"
      },
      "source": [
        "images[12].shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1856, 2784, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rwPzPX6jxuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0a84c9c-92ca-434d-8e27-2cc466e3b7b9"
      },
      "source": [
        "images[13].shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2592, 3872, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfg7XQaSkB4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b0eddfd-127d-4762-8be9-be5bf0ccd116"
      },
      "source": [
        "images[14].shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2673, 3382, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwoGv2ikixKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97453612-7c80-4773-fde5-3b90962950d8"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A15S4y9engjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list = []\n",
        "resized_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnigL94Hl5yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list = []\n",
        "resized_list = []\n",
        "for image in images:\n",
        "  image = resize(image, (256,256,3))\n",
        "  #image = image.resize((1500, 1500, 3))\n",
        "  resized_list.append(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r69_vtvQp4gG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b5cd564-2ad4-43b3-ced6-4a73c9103de8"
      },
      "source": [
        "resized_list"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157]],\n",
              " \n",
              "        [[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157]],\n",
              " \n",
              "        [[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157],\n",
              "         [0.00392157, 0.00392157, 0.00392157]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.08235294, 0.08627451, 0.0627451 ],\n",
              "         [0.06344063, 0.0673622 , 0.04383279],\n",
              "         [0.06419271, 0.06811428, 0.04458487],\n",
              "         ...,\n",
              "         [0.11619945, 0.11619945, 0.07698376],\n",
              "         [0.11227788, 0.11227788, 0.07058824],\n",
              "         [0.11619945, 0.11619945, 0.0745098 ]],\n",
              " \n",
              "        [[0.0745233 , 0.07844487, 0.05491545],\n",
              "         [0.05882353, 0.0627451 , 0.03921569],\n",
              "         [0.0627451 , 0.06666667, 0.0400644 ],\n",
              "         ...,\n",
              "         [0.11764706, 0.11764706, 0.07459406],\n",
              "         [0.11764706, 0.11764706, 0.07058824],\n",
              "         [0.11380974, 0.11380974, 0.06675092]],\n",
              " \n",
              "        [[0.05754442, 0.06146599, 0.03814144],\n",
              "         [0.05098039, 0.05490196, 0.03009344],\n",
              "         [0.05490196, 0.05882353, 0.03401501],\n",
              "         ...,\n",
              "         [0.10588235, 0.10588235, 0.06146599],\n",
              "         [0.10980392, 0.10980392, 0.0627451 ],\n",
              "         [0.10980392, 0.10980392, 0.0627451 ]]]),\n",
              " array([[[0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         ...,\n",
              "         [0.14126623, 0.27058824, 0.23921569],\n",
              "         [0.11856618, 0.24774816, 0.21158878],\n",
              "         [0.09411765, 0.21989626, 0.18460215]],\n",
              " \n",
              "        [[0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         ...,\n",
              "         [0.1372549 , 0.27801131, 0.23682598],\n",
              "         [0.12156863, 0.2627451 , 0.22692321],\n",
              "         [0.10524687, 0.24731134, 0.20720765]],\n",
              " \n",
              "        [[0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         [0.96078431, 0.95294118, 0.96470588],\n",
              "         ...,\n",
              "         [0.1254902 , 0.26781556, 0.22968295],\n",
              "         [0.10980392, 0.25517123, 0.21568627],\n",
              "         [0.10196078, 0.24313725, 0.2       ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.04313725, 0.11372549, 0.07058824],\n",
              "         [0.05098039, 0.11464461, 0.0745098 ],\n",
              "         [0.06427696, 0.13164374, 0.08458491],\n",
              "         ...,\n",
              "         [0.52048555, 0.48350184, 0.37930908],\n",
              "         [0.54532782, 0.50676198, 0.41199449],\n",
              "         [0.57731311, 0.53703829, 0.45574449]],\n",
              " \n",
              "        [[0.04705882, 0.11049326, 0.07058824],\n",
              "         [0.05098039, 0.11764706, 0.0745098 ],\n",
              "         [0.07058824, 0.14117647, 0.09172794],\n",
              "         ...,\n",
              "         [0.51764706, 0.48977601, 0.38362439],\n",
              "         [0.53580801, 0.50179922, 0.39931066],\n",
              "         [0.56793811, 0.53625919, 0.43758449]],\n",
              " \n",
              "        [[0.05882353, 0.11787684, 0.07843137],\n",
              "         [0.05490196, 0.12266367, 0.07843137],\n",
              "         [0.07058824, 0.14117647, 0.09172794],\n",
              "         ...,\n",
              "         [0.49411765, 0.47428002, 0.36078431],\n",
              "         [0.5058285 , 0.4812579 , 0.36470588],\n",
              "         [0.52910539, 0.50536415, 0.38792892]]]),\n",
              " array([[[0.5372549 , 0.7254902 , 0.12941176],\n",
              "         [0.54117647, 0.7254902 , 0.1372549 ],\n",
              "         [0.55686275, 0.73137255, 0.14901961],\n",
              "         ...,\n",
              "         [0.52156863, 0.6745098 , 0.18676471],\n",
              "         [0.52941176, 0.6745098 , 0.19607843],\n",
              "         [0.51764706, 0.66127451, 0.18431373]],\n",
              " \n",
              "        [[0.52941176, 0.72156863, 0.12941176],\n",
              "         [0.53039216, 0.72156863, 0.13431373],\n",
              "         [0.54166667, 0.72156863, 0.14166667],\n",
              "         ...,\n",
              "         [0.54117647, 0.69019608, 0.21568627],\n",
              "         [0.54068627, 0.68627451, 0.21127451],\n",
              "         [0.52696078, 0.67401961, 0.1995098 ]],\n",
              " \n",
              "        [[0.52156863, 0.70588235, 0.1254902 ],\n",
              "         [0.52156863, 0.70588235, 0.12941176],\n",
              "         [0.52156863, 0.70196078, 0.1372549 ],\n",
              "         ...,\n",
              "         [0.55196078, 0.69803922, 0.23088235],\n",
              "         [0.54509804, 0.69411765, 0.22352941],\n",
              "         [0.5372549 , 0.68627451, 0.21764706]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.07843137, 0.09509804, 0.05539216],\n",
              "         [0.06764706, 0.06666667, 0.01862745],\n",
              "         [0.08382353, 0.07058824, 0.00392157],\n",
              "         ...,\n",
              "         [0.36372549, 0.29313725, 0.16715686],\n",
              "         [0.28627451, 0.22254902, 0.14019608],\n",
              "         [0.17794118, 0.14411765, 0.09313725]],\n",
              " \n",
              "        [[0.10980392, 0.14901961, 0.11862745],\n",
              "         [0.09117647, 0.11764706, 0.07745098],\n",
              "         [0.06764706, 0.07941176, 0.02009804],\n",
              "         ...,\n",
              "         [0.28088235, 0.21176471, 0.13431373],\n",
              "         [0.19705882, 0.14607843, 0.09607843],\n",
              "         [0.12352941, 0.10588235, 0.07303922]],\n",
              " \n",
              "        [[0.11960784, 0.16666667, 0.12745098],\n",
              "         [0.12892157, 0.17009804, 0.11568627],\n",
              "         [0.09558824, 0.1245098 , 0.0504902 ],\n",
              "         ...,\n",
              "         [0.21421569, 0.1495098 , 0.10931373],\n",
              "         [0.21176471, 0.16372549, 0.14019608],\n",
              "         [0.15784314, 0.13284314, 0.12107843]]]),\n",
              " array([[[0.10192769, 0.23529412, 0.1372549 ],\n",
              "         [0.10196078, 0.25098039, 0.1372549 ],\n",
              "         [0.10196078, 0.26693474, 0.14369944],\n",
              "         ...,\n",
              "         [0.08627451, 0.24313725, 0.12941176],\n",
              "         [0.08637378, 0.24463848, 0.12941176],\n",
              "         [0.09019608, 0.23529412, 0.12941176]],\n",
              " \n",
              "        [[0.10980392, 0.27117034, 0.14509804],\n",
              "         [0.10588235, 0.25940564, 0.13781313],\n",
              "         [0.10196078, 0.26693474, 0.14117647],\n",
              "         ...,\n",
              "         [0.08627451, 0.24705882, 0.13333333],\n",
              "         [0.08235294, 0.25487809, 0.13333333],\n",
              "         [0.08235294, 0.25098039, 0.13333333]],\n",
              " \n",
              "        [[0.10588235, 0.27058824, 0.14117647],\n",
              "         [0.10196078, 0.27434896, 0.14117647],\n",
              "         [0.10196078, 0.27477788, 0.14117647],\n",
              "         ...,\n",
              "         [0.07843137, 0.25098039, 0.12941176],\n",
              "         [0.07843137, 0.24705882, 0.13333333],\n",
              "         [0.08235294, 0.25098039, 0.13333333]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         ...,\n",
              "         [0.089928  , 0.28634344, 0.14149044],\n",
              "         [0.1214216 , 0.3452742 , 0.18841146],\n",
              "         [0.12941176, 0.34476564, 0.2       ]],\n",
              " \n",
              "        [[0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         ...,\n",
              "         [0.1129151 , 0.32464001, 0.17873158],\n",
              "         [0.12941176, 0.35294118, 0.20784314],\n",
              "         [0.1254902 , 0.33333333, 0.20005362]],\n",
              " \n",
              "        [[0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         [0.11372549, 0.11764706, 0.13333333],\n",
              "         ...,\n",
              "         [0.13306526, 0.35294118, 0.21009803],\n",
              "         [0.12957261, 0.34277697, 0.21568627],\n",
              "         [0.12941176, 0.33333333, 0.20784314]]]),\n",
              " array([[[0.40929841, 0.40392157, 0.39607843],\n",
              "         [0.41176471, 0.39215686, 0.38039216],\n",
              "         [0.39656863, 0.37899816, 0.36723346],\n",
              "         ...,\n",
              "         [0.05098039, 0.04705882, 0.03137255],\n",
              "         [0.05490196, 0.04705882, 0.03872549],\n",
              "         [0.05490196, 0.04705882, 0.04226409]],\n",
              " \n",
              "        [[0.40784314, 0.39407169, 0.39460784],\n",
              "         [0.40381434, 0.37254902, 0.36470588],\n",
              "         [0.38861826, 0.36116728, 0.35686275],\n",
              "         ...,\n",
              "         [0.05882353, 0.04705882, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.03797488],\n",
              "         [0.05490196, 0.04705882, 0.04113051]],\n",
              " \n",
              "        [[0.4       , 0.38431373, 0.38419118],\n",
              "         [0.41176471, 0.38823529, 0.38432904],\n",
              "         [0.39656863, 0.37706801, 0.37256434],\n",
              "         ...,\n",
              "         [0.0470435 , 0.04705882, 0.03529412],\n",
              "         [0.04718137, 0.05098039, 0.03921569],\n",
              "         [0.04705882, 0.04705882, 0.03921569]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.01806066, 0.01568627, 0.01176471],\n",
              "         [0.01568627, 0.01568627, 0.01176471],\n",
              "         [0.01178002, 0.01568627, 0.01176471],\n",
              "         ...,\n",
              "         [0.27058824, 0.29803922, 0.14117647],\n",
              "         [0.27843137, 0.2902114 , 0.14509804],\n",
              "         [0.27058824, 0.29019608, 0.14509804]],\n",
              " \n",
              "        [[0.02238051, 0.01568627, 0.00784314],\n",
              "         [0.01654412, 0.01568627, 0.01176471],\n",
              "         [0.01568627, 0.01568627, 0.01176471],\n",
              "         ...,\n",
              "         [0.26666667, 0.29411765, 0.14117647],\n",
              "         [0.2745098 , 0.29019608, 0.14509804],\n",
              "         [0.27058824, 0.2932598 , 0.14117647]],\n",
              " \n",
              "        [[0.01568627, 0.01568627, 0.01176471],\n",
              "         [0.01801471, 0.01568627, 0.01568627],\n",
              "         [0.01821385, 0.01960784, 0.01176471],\n",
              "         ...,\n",
              "         [0.27291667, 0.29803922, 0.1372549 ],\n",
              "         [0.27058824, 0.29803922, 0.14117647],\n",
              "         [0.27058824, 0.29411765, 0.14117647]]]),\n",
              " array([[[0.43137255, 0.41176471, 0.39142401],\n",
              "         [0.44237898, 0.42745098, 0.41176471],\n",
              "         [0.45882353, 0.45490196, 0.44297188],\n",
              "         ...,\n",
              "         [0.35294118, 0.35294118, 0.35294118],\n",
              "         [0.34901961, 0.34901961, 0.34901961],\n",
              "         [0.34901961, 0.34901961, 0.34901961]],\n",
              " \n",
              "        [[0.42745098, 0.40784314, 0.39190411],\n",
              "         [0.43921569, 0.42745098, 0.41176471],\n",
              "         [0.45882353, 0.45490196, 0.44187347],\n",
              "         ...,\n",
              "         [0.35559896, 0.35559896, 0.35559896],\n",
              "         [0.35294118, 0.35294118, 0.35294118],\n",
              "         [0.35294118, 0.35294118, 0.35294118]],\n",
              " \n",
              "        [[0.43111979, 0.4141652 , 0.39607843],\n",
              "         [0.44237898, 0.43137255, 0.414928  ],\n",
              "         [0.45490196, 0.4518992 , 0.44187347],\n",
              "         ...,\n",
              "         [0.35686275, 0.35686275, 0.35686275],\n",
              "         [0.35686275, 0.35686275, 0.35550705],\n",
              "         [0.35951599, 0.35951599, 0.35686275]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.89956029, 0.85233609, 0.80553002],\n",
              "         [0.87843137, 0.82745098, 0.79215686],\n",
              "         [0.88583761, 0.84579504, 0.81050092],\n",
              "         ...,\n",
              "         [0.46453769, 0.45359988, 0.44313725],\n",
              "         [0.47194393, 0.4641008 , 0.44449295],\n",
              "         [0.53902874, 0.51533395, 0.47219669]],\n",
              " \n",
              "        [[0.90375306, 0.86676589, 0.82914403],\n",
              "         [0.86866678, 0.81990552, 0.78431373],\n",
              "         [0.87766372, 0.8379519 , 0.8       ],\n",
              "         ...,\n",
              "         [0.60840993, 0.55792567, 0.50798866],\n",
              "         [0.57263327, 0.55302543, 0.52557445],\n",
              "         [0.5710095 , 0.54757931, 0.51387902]],\n",
              " \n",
              "        [[0.87846445, 0.83602697, 0.80809589],\n",
              "         [0.86708061, 0.82343018, 0.78813607],\n",
              "         [0.87843137, 0.83921569, 0.8       ],\n",
              "         ...,\n",
              "         [0.58458946, 0.56412065, 0.5372549 ],\n",
              "         [0.55854814, 0.53776808, 0.51475184],\n",
              "         [0.58848805, 0.56814735, 0.52966452]]]),\n",
              " array([[[0.78468137, 0.7656633 , 0.57588082],\n",
              "         [0.74332874, 0.75686275, 0.54632353],\n",
              "         [0.73063725, 0.75305607, 0.53848039],\n",
              "         ...,\n",
              "         [0.35575214, 0.41960784, 0.29300705],\n",
              "         [0.34294577, 0.40392157, 0.27235754],\n",
              "         [0.3254902 , 0.39215686, 0.25098039]],\n",
              " \n",
              "        [[0.81463695, 0.77647059, 0.61071538],\n",
              "         [0.77389706, 0.76862745, 0.57630974],\n",
              "         [0.73357843, 0.75686275, 0.54924173],\n",
              "         ...,\n",
              "         [0.3372549 , 0.40392157, 0.27509957],\n",
              "         [0.32941176, 0.38839614, 0.25755974],\n",
              "         [0.32156863, 0.38536305, 0.24705882]],\n",
              " \n",
              "        [[0.80477941, 0.77034314, 0.60343903],\n",
              "         [0.73639706, 0.75149357, 0.55541513],\n",
              "         [0.6879902 , 0.7370481 , 0.52328431],\n",
              "         ...,\n",
              "         [0.30980392, 0.38210784, 0.25098039],\n",
              "         [0.30980392, 0.37254902, 0.23921569],\n",
              "         [0.30980392, 0.37254902, 0.23137255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.65796569, 0.72941176, 0.61960784],\n",
              "         [0.63213082, 0.69299173, 0.585072  ],\n",
              "         [0.56262255, 0.62536765, 0.49987745],\n",
              "         ...,\n",
              "         [0.48627451, 0.50588235, 0.38039216],\n",
              "         [0.47058824, 0.49411765, 0.36411612],\n",
              "         [0.44705882, 0.47316942, 0.34117647]],\n",
              " \n",
              "        [[0.65117188, 0.70980392, 0.60392157],\n",
              "         [0.60526961, 0.66008732, 0.55428922],\n",
              "         [0.51727941, 0.58762255, 0.45786612],\n",
              "         ...,\n",
              "         [0.4745098 , 0.49411765, 0.35686275],\n",
              "         [0.45490196, 0.47834712, 0.33574602],\n",
              "         [0.43529412, 0.45962776, 0.32132353]],\n",
              " \n",
              "        [[0.64705882, 0.67784161, 0.56593137],\n",
              "         [0.58566176, 0.61610754, 0.52764246],\n",
              "         [0.48701746, 0.54595588, 0.43063725],\n",
              "         ...,\n",
              "         [0.48627451, 0.50196078, 0.36078431],\n",
              "         [0.4645144 , 0.48412224, 0.33291207],\n",
              "         [0.44313725, 0.4627451 , 0.31372549]]]),\n",
              " array([[[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.43796369, 0.44871324, 0.46573223],\n",
              "         [0.35199507, 0.37041973, 0.37944605],\n",
              "         [0.32156863, 0.34117647, 0.34117647]],\n",
              " \n",
              "        [[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.44614264, 0.45490196, 0.47058824],\n",
              "         [0.38990939, 0.40350797, 0.4134388 ],\n",
              "         [0.33391909, 0.33784066, 0.33784066]],\n",
              " \n",
              "        [[0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.43529412, 0.44705882, 0.46392463],\n",
              "         [0.43191163, 0.44556998, 0.4627451 ],\n",
              "         [0.39903493, 0.4029565 , 0.4147212 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.23529412, 0.31490502, 0.00784314],\n",
              "         [0.25490196, 0.32941176, 0.01176471],\n",
              "         [0.24705882, 0.3254902 , 0.00694466],\n",
              "         ...,\n",
              "         [0.61176471, 0.67659846, 0.45396752],\n",
              "         [0.57951606, 0.62924326, 0.3553462 ],\n",
              "         [0.51432292, 0.58198942, 0.25157782]],\n",
              " \n",
              "        [[0.21568627, 0.29470341, 0.00392157],\n",
              "         [0.25669424, 0.33329175, 0.02928485],\n",
              "         [0.25098039, 0.33333333, 0.01568627],\n",
              "         ...,\n",
              "         [0.61568627, 0.68627451, 0.4696538 ],\n",
              "         [0.586106  , 0.64500613, 0.38009015],\n",
              "         [0.51432292, 0.5842488 , 0.24825368]],\n",
              " \n",
              "        [[0.204519  , 0.27843137, 0.        ],\n",
              "         [0.23255573, 0.30706554, 0.01496265],\n",
              "         [0.25098039, 0.3290942 , 0.01960784],\n",
              "         ...,\n",
              "         [0.59805041, 0.67843137, 0.46573223],\n",
              "         [0.56516544, 0.64028434, 0.38005515],\n",
              "         [0.49338235, 0.56789216, 0.24041054]]]),\n",
              " array([[[0.49803922, 0.59215686, 0.41176471],\n",
              "         [0.50196078, 0.59607843, 0.41568627],\n",
              "         [0.49803922, 0.6       , 0.41176471],\n",
              "         ...,\n",
              "         [0.56862745, 0.64705882, 0.43578431],\n",
              "         [0.56078431, 0.63921569, 0.42843137],\n",
              "         [0.55294118, 0.63137255, 0.42352941]],\n",
              " \n",
              "        [[0.49803922, 0.59215686, 0.41176471],\n",
              "         [0.49803922, 0.59607843, 0.41568627],\n",
              "         [0.49803922, 0.6       , 0.41568627],\n",
              "         ...,\n",
              "         [0.56862745, 0.64705882, 0.43921569],\n",
              "         [0.56078431, 0.63921569, 0.43137255],\n",
              "         [0.55686275, 0.63529412, 0.42745098]],\n",
              " \n",
              "        [[0.49901961, 0.59607843, 0.41176471],\n",
              "         [0.49803922, 0.6       , 0.41568627],\n",
              "         [0.49803922, 0.6       , 0.41568627],\n",
              "         ...,\n",
              "         [0.56862745, 0.64705882, 0.43921569],\n",
              "         [0.56078431, 0.63921569, 0.43137255],\n",
              "         [0.55686275, 0.63529412, 0.42745098]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.10588235, 0.16862745, 0.2745098 ],\n",
              "         [0.10196078, 0.17598039, 0.2745098 ],\n",
              "         [0.09803922, 0.17647059, 0.2745098 ],\n",
              "         ...,\n",
              "         [0.09019608, 0.2       , 0.29411765],\n",
              "         [0.08933824, 0.19607843, 0.29411765],\n",
              "         [0.09166667, 0.19607843, 0.29411765]],\n",
              " \n",
              "        [[0.10980392, 0.17254902, 0.2745098 ],\n",
              "         [0.10196078, 0.17647059, 0.2745098 ],\n",
              "         [0.10196078, 0.18039216, 0.2745098 ],\n",
              "         ...,\n",
              "         [0.09803922, 0.19607843, 0.29019608],\n",
              "         [0.09019608, 0.19215686, 0.29803922],\n",
              "         [0.09803922, 0.19215686, 0.29705882]],\n",
              " \n",
              "        [[0.10796569, 0.17107843, 0.2745098 ],\n",
              "         [0.10196078, 0.17647059, 0.2745098 ],\n",
              "         [0.10588235, 0.18039216, 0.2745098 ],\n",
              "         ...,\n",
              "         [0.09803922, 0.19607843, 0.29019608],\n",
              "         [0.09313725, 0.19215686, 0.29411765],\n",
              "         [0.09803922, 0.18823529, 0.29411765]]]),\n",
              " array([[[0.00392157, 0.01960784, 0.        ],\n",
              "         [0.00392157, 0.01960784, 0.        ],\n",
              "         [0.00392157, 0.02352941, 0.        ],\n",
              "         ...,\n",
              "         [0.34901961, 0.35686275, 0.2939951 ],\n",
              "         [0.35367647, 0.3604856 , 0.27058824],\n",
              "         [0.36862745, 0.37647059, 0.25894608]],\n",
              " \n",
              "        [[0.00392157, 0.01960784, 0.        ],\n",
              "         [0.00392157, 0.01960784, 0.        ],\n",
              "         [0.00392157, 0.02352941, 0.        ],\n",
              "         ...,\n",
              "         [0.35625   , 0.35259651, 0.26088388],\n",
              "         [0.36642157, 0.3625    , 0.25098039],\n",
              "         [0.36862745, 0.36642157, 0.24093137]],\n",
              " \n",
              "        [[0.00392157, 0.01960784, 0.        ],\n",
              "         [0.00784314, 0.02352941, 0.        ],\n",
              "         [0.01176471, 0.02745098, 0.00392157],\n",
              "         ...,\n",
              "         [0.31417739, 0.31731771, 0.25964308],\n",
              "         [0.31789216, 0.31397059, 0.23958333],\n",
              "         [0.31397059, 0.30612745, 0.21544884]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.09411765, 0.1254902 , 0.11372549],\n",
              "         [0.09019608, 0.1254902 , 0.11372549],\n",
              "         [0.09803922, 0.1254902 , 0.11764706],\n",
              "         ...,\n",
              "         [0.2817402 , 0.25408241, 0.18431373],\n",
              "         [0.29411765, 0.25882353, 0.19571078],\n",
              "         [0.29411765, 0.25490196, 0.2       ]],\n",
              " \n",
              "        [[0.09411765, 0.12156863, 0.10980392],\n",
              "         [0.09019608, 0.12156863, 0.11372549],\n",
              "         [0.09411765, 0.1254902 , 0.11372549],\n",
              "         ...,\n",
              "         [0.27244945, 0.24313725, 0.18039216],\n",
              "         [0.28435202, 0.25098039, 0.19215686],\n",
              "         [0.28627451, 0.25098039, 0.19436275]],\n",
              " \n",
              "        [[0.09411765, 0.11764706, 0.10980392],\n",
              "         [0.09019608, 0.11764706, 0.10980392],\n",
              "         [0.09019608, 0.12156863, 0.10980392],\n",
              "         ...,\n",
              "         [0.25552237, 0.23468137, 0.17597273],\n",
              "         [0.27058824, 0.24387255, 0.18431373],\n",
              "         [0.2745098 , 0.24705882, 0.18897059]]]),\n",
              " array([[[0.51323529, 0.57205882, 0.53333333],\n",
              "         [0.50980392, 0.56862745, 0.53284314],\n",
              "         [0.505598  , 0.56470588, 0.53333333],\n",
              "         ...,\n",
              "         [0.14901961, 0.15879385, 0.20441176],\n",
              "         [0.15294118, 0.16862745, 0.21568627],\n",
              "         [0.16078431, 0.1733274 , 0.21960784]],\n",
              " \n",
              "        [[0.47708429, 0.54509804, 0.50588235],\n",
              "         [0.4745098 , 0.54117647, 0.50196078],\n",
              "         [0.4745098 , 0.54117647, 0.50196078],\n",
              "         ...,\n",
              "         [0.2       , 0.19607843, 0.23676471],\n",
              "         [0.20147059, 0.19816655, 0.23529412],\n",
              "         [0.20539216, 0.20392157, 0.23529412]],\n",
              " \n",
              "        [[0.46666667, 0.5372549 , 0.49803922],\n",
              "         [0.47058824, 0.5372549 , 0.50196078],\n",
              "         [0.47058824, 0.54117647, 0.50196078],\n",
              "         ...,\n",
              "         [0.21176471, 0.20846067, 0.24455902],\n",
              "         [0.21568627, 0.21568627, 0.23529412],\n",
              "         [0.21568627, 0.21176471, 0.23137255]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.49411765, 0.53500977, 0.42757449],\n",
              "         [0.49166667, 0.5254902 , 0.40539216],\n",
              "         [0.48154871, 0.51230373, 0.38681353],\n",
              "         ...,\n",
              "         [0.45098039, 0.49656863, 0.36862745],\n",
              "         [0.4495098 , 0.49411765, 0.36470588],\n",
              "         [0.45490196, 0.49803922, 0.36470588]],\n",
              " \n",
              "        [[0.41862745, 0.48137255, 0.38186275],\n",
              "         [0.44570791, 0.4949707 , 0.37009804],\n",
              "         [0.45306851, 0.49166667, 0.34906844],\n",
              "         ...,\n",
              "         [0.41857862, 0.46666667, 0.33872549],\n",
              "         [0.41715686, 0.46421569, 0.33872549],\n",
              "         [0.41973135, 0.46813725, 0.33480392]],\n",
              " \n",
              "        [[0.30637255, 0.36911765, 0.26323529],\n",
              "         [0.31850394, 0.38088235, 0.25931373],\n",
              "         [0.3377451 , 0.38872549, 0.2335095 ],\n",
              "         ...,\n",
              "         [0.31029412, 0.3396762 , 0.21246075],\n",
              "         [0.31557043, 0.35870768, 0.23578431],\n",
              "         [0.32598039, 0.37303922, 0.23970588]]]),\n",
              " array([[[0.08235294, 0.07058824, 0.05114124],\n",
              "         [0.10588235, 0.09552711, 0.07058824],\n",
              "         [0.15210096, 0.1419807 , 0.09803922],\n",
              "         ...,\n",
              "         [0.15294118, 0.17647059, 0.1372549 ],\n",
              "         [0.15294118, 0.17254902, 0.13333333],\n",
              "         [0.14901961, 0.16862745, 0.12941176]],\n",
              " \n",
              "        [[0.07859222, 0.06682751, 0.05098039],\n",
              "         [0.10588235, 0.09852175, 0.07058824],\n",
              "         [0.1537454 , 0.14590227, 0.09884344],\n",
              "         ...,\n",
              "         [0.15686275, 0.18039216, 0.1372549 ],\n",
              "         [0.14901961, 0.17254902, 0.13333333],\n",
              "         [0.14509804, 0.16862745, 0.12941176]],\n",
              " \n",
              "        [[0.0745098 , 0.06666667, 0.05098039],\n",
              "         [0.10636489, 0.10196078, 0.07058824],\n",
              "         [0.1537454 , 0.14982384, 0.09884344],\n",
              "         ...,\n",
              "         [0.15346581, 0.17647059, 0.1372549 ],\n",
              "         [0.14901961, 0.17254902, 0.13333333],\n",
              "         [0.14509804, 0.16862745, 0.12941176]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.07058824, 0.07058824, 0.07058824],\n",
              "         [0.0745098 , 0.0745098 , 0.0745098 ],\n",
              "         [0.07843137, 0.07843137, 0.07843137],\n",
              "         ...,\n",
              "         [0.16862745, 0.17254902, 0.21568627],\n",
              "         [0.17254902, 0.17254902, 0.21792971],\n",
              "         [0.17254902, 0.17254902, 0.21960784]],\n",
              " \n",
              "        [[0.07058824, 0.07058824, 0.07058824],\n",
              "         [0.0745098 , 0.0745098 , 0.0745098 ],\n",
              "         [0.07843137, 0.07843137, 0.07843137],\n",
              "         ...,\n",
              "         [0.16862745, 0.17254902, 0.21568627],\n",
              "         [0.17254902, 0.17254902, 0.21568627],\n",
              "         [0.17254902, 0.17254902, 0.21960784]],\n",
              " \n",
              "        [[0.07058824, 0.07058824, 0.07058824],\n",
              "         [0.0745098 , 0.0745098 , 0.0745098 ],\n",
              "         [0.07556679, 0.07843137, 0.07843137],\n",
              "         ...,\n",
              "         [0.16862745, 0.16862745, 0.21568627],\n",
              "         [0.17254902, 0.17254902, 0.21960784],\n",
              "         [0.17254902, 0.17254902, 0.21960784]]]),\n",
              " array([[[3.45067402e-01, 5.28890931e-01, 1.17892157e-01],\n",
              "         [3.37990196e-01, 5.26133578e-01, 1.14797794e-01],\n",
              "         [3.43872549e-01, 5.17647059e-01, 9.50980392e-02],\n",
              "         ...,\n",
              "         [3.52941176e-01, 5.60784314e-01, 1.53492647e-02],\n",
              "         [3.64705882e-01, 5.65349265e-01, 3.48958333e-02],\n",
              "         [3.64705882e-01, 5.75980392e-01, 5.90379902e-02]],\n",
              " \n",
              "        [[3.37500000e-01, 5.25827206e-01, 1.98284314e-01],\n",
              "         [3.40655637e-01, 5.24509804e-01, 2.08088235e-01],\n",
              "         [3.49264706e-01, 5.22273284e-01, 1.69577206e-01],\n",
              "         ...,\n",
              "         [3.45098039e-01, 5.35784314e-01, 7.65931373e-04],\n",
              "         [3.55392157e-01, 5.35784314e-01, 1.02941176e-02],\n",
              "         [3.59313725e-01, 5.34313725e-01, 3.00551471e-02]],\n",
              " \n",
              "        [[4.76470588e-01, 6.40349265e-01, 4.09803922e-01],\n",
              "         [4.34344363e-01, 6.05637255e-01, 3.51470588e-01],\n",
              "         [4.15196078e-01, 5.89215686e-01, 2.72794118e-01],\n",
              "         ...,\n",
              "         [3.26960784e-01, 4.84528186e-01, 0.00000000e+00],\n",
              "         [3.03186275e-01, 4.46844363e-01, 2.75735294e-04],\n",
              "         [2.71568627e-01, 3.83088235e-01, 5.39215686e-03]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[1.47702206e-01, 2.18290441e-01, 2.62254902e-02],\n",
              "         [7.23039216e-02, 2.07628676e-01, 1.10294118e-02],\n",
              "         [3.50735294e-01, 5.41207108e-01, 1.49724265e-01],\n",
              "         ...,\n",
              "         [1.97303922e-01, 1.81617647e-01, 5.73529412e-02],\n",
              "         [2.11764706e-01, 1.91881127e-01, 5.46262255e-02],\n",
              "         [1.87990196e-01, 1.63082108e-01, 3.75919118e-02]],\n",
              " \n",
              "        [[1.25582108e-01, 1.92310049e-01, 7.07414216e-02],\n",
              "         [6.32046569e-02, 1.94607843e-01, 1.14889706e-02],\n",
              "         [3.40441176e-01, 5.29901961e-01, 1.45802696e-01],\n",
              "         ...,\n",
              "         [1.71568627e-01, 1.44577206e-01, 3.28431373e-02],\n",
              "         [1.71568627e-01, 1.40196078e-01, 2.10784314e-02],\n",
              "         [1.59712010e-01, 1.30882353e-01, 2.10784314e-02]],\n",
              " \n",
              "        [[2.31587010e-01, 3.13939951e-01, 1.49234069e-01],\n",
              "         [6.59313725e-02, 1.89215686e-01, 1.56862745e-02],\n",
              "         [3.37009804e-01, 5.29013480e-01, 1.50735294e-01],\n",
              "         ...,\n",
              "         [1.42738971e-01, 1.13725490e-01, 1.96078431e-02],\n",
              "         [1.52941176e-01, 1.17647059e-01, 1.45526961e-02],\n",
              "         [1.49019608e-01, 1.17647059e-01, 1.17647059e-02]]]),\n",
              " array([[[0.33333333, 0.43137255, 0.07843137],\n",
              "         [0.33333333, 0.43529412, 0.07843137],\n",
              "         [0.3372549 , 0.43529412, 0.07843137],\n",
              "         ...,\n",
              "         [0.34509804, 0.42745098, 0.14117647],\n",
              "         [0.34117647, 0.42745098, 0.14117647],\n",
              "         [0.33739277, 0.42745098, 0.14289216]],\n",
              " \n",
              "        [[0.31887255, 0.42745098, 0.06666667],\n",
              "         [0.3254902 , 0.43137255, 0.07058824],\n",
              "         [0.32755821, 0.43137255, 0.0745098 ],\n",
              "         ...,\n",
              "         [0.34901961, 0.42745098, 0.1372549 ],\n",
              "         [0.34509804, 0.43137255, 0.14117647],\n",
              "         [0.34117647, 0.43137255, 0.14509804]],\n",
              " \n",
              "        [[0.31372549, 0.42745098, 0.0627451 ],\n",
              "         [0.32156863, 0.42745098, 0.06288297],\n",
              "         [0.31838235, 0.43037684, 0.06666667],\n",
              "         ...,\n",
              "         [0.34509804, 0.43137255, 0.1372549 ],\n",
              "         [0.34509804, 0.43455882, 0.1379902 ],\n",
              "         [0.34509804, 0.43529412, 0.14117647]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.25886949, 0.36862745, 0.09019608],\n",
              "         [0.27843137, 0.38431373, 0.10196078],\n",
              "         [0.29192708, 0.39630821, 0.10588235],\n",
              "         ...,\n",
              "         [0.38431373, 0.43529412, 0.11787684],\n",
              "         [0.38445159, 0.43529412, 0.12156863],\n",
              "         [0.38112745, 0.43137255, 0.11764706]],\n",
              " \n",
              "        [[0.2745098 , 0.36348039, 0.10588235],\n",
              "         [0.29411765, 0.38874081, 0.11372549],\n",
              "         [0.30318627, 0.41176471, 0.10588235],\n",
              "         ...,\n",
              "         [0.39215686, 0.43921569, 0.1254902 ],\n",
              "         [0.39215686, 0.43651961, 0.12156863],\n",
              "         [0.39215686, 0.43529412, 0.11764706]],\n",
              " \n",
              "        [[0.28638174, 0.32769608, 0.11383272],\n",
              "         [0.31372549, 0.36723346, 0.1368413 ],\n",
              "         [0.30196078, 0.40274203, 0.09563419],\n",
              "         ...,\n",
              "         [0.39848346, 0.44436275, 0.11985294],\n",
              "         [0.39215686, 0.43921569, 0.11764706],\n",
              "         [0.39436275, 0.43529412, 0.11372549]]]),\n",
              " array([[[0.09008056, 0.10196078, 0.01176471],\n",
              "         [0.09019608, 0.10588235, 0.00784314],\n",
              "         [0.09411765, 0.10980392, 0.01176471],\n",
              "         ...,\n",
              "         [0.03529412, 0.05882353, 0.        ],\n",
              "         [0.03137255, 0.05490196, 0.        ],\n",
              "         [0.03137255, 0.05490196, 0.        ]],\n",
              " \n",
              "        [[0.09019608, 0.10588235, 0.01568627],\n",
              "         [0.09019608, 0.10588235, 0.01176471],\n",
              "         [0.09411765, 0.10980392, 0.00939621],\n",
              "         ...,\n",
              "         [0.03921569, 0.0627451 , 0.        ],\n",
              "         [0.03529412, 0.05882353, 0.        ],\n",
              "         [0.03529412, 0.05553768, 0.        ]],\n",
              " \n",
              "        [[0.09411765, 0.10980392, 0.01568627],\n",
              "         [0.09411765, 0.10980392, 0.01176471],\n",
              "         [0.09411765, 0.10980392, 0.00784314],\n",
              "         ...,\n",
              "         [0.04240235, 0.0627451 , 0.        ],\n",
              "         [0.03529412, 0.05882353, 0.        ],\n",
              "         [0.03529412, 0.05882353, 0.        ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.16445627, 0.1368413 , 0.        ],\n",
              "         [0.12263151, 0.09729037, 0.00392157],\n",
              "         [0.14005782, 0.10795037, 0.00392157],\n",
              "         ...,\n",
              "         [0.2       , 0.16315104, 0.05098039],\n",
              "         [0.20392157, 0.16470588, 0.05651984],\n",
              "         [0.20784314, 0.16862745, 0.0627451 ]],\n",
              " \n",
              "        [[0.1218578 , 0.09832838, 0.        ],\n",
              "         [0.09763528, 0.07122396, 0.00392157],\n",
              "         [0.12819393, 0.09289982, 0.00392157],\n",
              "         ...,\n",
              "         [0.19607843, 0.15686275, 0.04705882],\n",
              "         [0.19832461, 0.16078431, 0.05098039],\n",
              "         [0.2       , 0.16078431, 0.05490196]],\n",
              " \n",
              "        [[0.0381204 , 0.0263557 , 0.        ],\n",
              "         [0.03027727, 0.01658053, 0.        ],\n",
              "         [0.08147212, 0.05587469, 0.        ],\n",
              "         ...,\n",
              "         [0.19607843, 0.15686275, 0.04705882],\n",
              "         [0.19498315, 0.15576746, 0.04988511],\n",
              "         [0.19607843, 0.15686275, 0.05098039]]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "Your goal is to validly run ResNet50v2 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
        "\n",
        "*Hint* - ResNet 50v2 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals:* \n",
        "- Check for other things such as fish.\n",
        "- Print out the image with its predicted label\n",
        "- Wrap everything nicely in well documented fucntions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
        "# TODO - your code!\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU3f3vNelhPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the base model from the pre-trained model ResNet\n",
        "#input_shape= (256,256,3)\n",
        "base_model = tensorflow.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "176FgNRfm7Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnOrGLJGm7Tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aef31cd3-05f6-474e-b480-a8e1f73aa2aa"
      },
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDkbqe5Nz8-g",
        "colab_type": "text"
      },
      "source": [
        "# Could use more time on this part but was able to run tghrough. Looks like resizing hte images could have messed up accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ \n",
        "An autoencoder is really good for denoising an image. The *encoder* compresses the input data and the *decoder* does the reverse to produce the uncompressed version of the data to create a reconstruction of the input as accurately as possible. \n",
        "\n",
        "They are aalso good for image retrival where they can reverse image search for similar images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "  - My strongest skillset as a data scientist is my classification and regression machine learning predictions with Flask application components. I think this sets me apart from most as I am able to understand how to implement a classification problem with a user friendly application to back it.\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "  - I want to dive deeper into NN architectures and formats. I feel there is so much undernearth the hood going on that I can learn more about and possibly implement into other areas outside of data science. I want to also experiment with GPU's and become a more invested data scientist.\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "  - I think the industry of Data Science as a whole is continuing to bloom and can only grow in size and areas. I hope to be involved in system analytics and system analysis for space vehicles in the next five years. That is my dream field and feel there are many aspects in which I can contribute to in that industry.\n",
        "- What are the threats posed by AI to our society?\n",
        "  - I think job loss is a big issue that is factored into AI and then morality of how that AI will act or be unguarded with personal/important information it oversees. (Can not accidentally send out information or delete critical components) I also think another issue is legality of autonomous vehicles like Tesla or Bell (producing uber planes with some AI features) this could lead to some problems if an accident or malfunction occured. \n",
        "- How do you think we can counteract those threats? \n",
        "  - Obviously some of these problems are not really at the for front but are issues we can really get ourselves stuck in down the road. I think safety procautions, backups, and checks are critical to seeing information stored and saved properly. I also think AI for innovation can provide jobs in other ways so pushing for a better future is important too.\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "  - Never say never lol! But I would be interested to see what does come of it. It may be doable in time but I do not know.\n",
        "\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjwbqNFNPRrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e3b2bb18-2e30-4b3f-9f07-ac2edc9e288b"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}