{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "432A_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blakelobato/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/432A_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFyepYOrrDy_",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n",
        "- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n",
        "- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n",
        "\n",
        "\n",
        "You will apply three different CNN models to a binary image classification model using Keras. Classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "|Mountain (+)|Forest (-)|\n",
        "|---|---|\n",
        "|![](https://github.com/blakelobato/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data/mountain/art1131.jpg?raw=1)|![](https://github.com/blakelobato/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data/forest/cdmc317.jpg?raw=1)|\n",
        "\n",
        "The problem is realively difficult given that the sample is tiny: there are about 350 observations per class. This sample size might be something that you can expect with prototyping an image classification problem/solution at work. Get accustomed to evaluating several differnet possible models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m_397n7hrDzB"
      },
      "source": [
        "# Pre - Trained Model\n",
        "<a id=\"p1\"></a>\n",
        "\n",
        "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D()\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "```\n",
        "\n",
        "The `include_top` parameter in `ResNet50` will remove the full connected layers from the ResNet model. The next step is to turn off the training of the ResNet layers. We want to use the learned parameters without updating them in future training passes. \n",
        "\n",
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```\n",
        "\n",
        "Using the Keras functional API, we will need to additional additional full connected layers to our model. We we removed the top layers, we removed all preivous fully connected layers. In other words, we kept only the feature processing portions of our network. You can expert with additional layers beyond what's listed here. The `GlobalAveragePooling2D` layer functions as a really fancy flatten function by taking the average of each of the last convolutional layer outputs (which is two dimensional still). \n",
        "\n",
        "```python\n",
        "x = res.output\n",
        "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(res.input, predictions)\n",
        "```\n",
        "\n",
        "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "Steps to complete assignment: \n",
        "1. Load in Image Data into numpy arrays (`X`) \n",
        "2. Create a `y` for the labels\n",
        "3. Train your model with pretrained layers from resnet\n",
        "4. Report your model's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k3tKgU5wWN5",
        "colab_type": "code",
        "outputId": "a0a8cc58-05e4-4af1-945f-f3172f5fff67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s33-n43YyL4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "DATASET_PATH  = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf655mwR5dEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread_collection\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MimMREHxrDzC",
        "colab_type": "text"
      },
      "source": [
        "## Load in Data\n",
        "\n",
        "![skimage-logo](https://scikit-image.org/_static/img/logo.png)\n",
        "\n",
        "Check out out [`skimage`](https://scikit-image.org/) for useful functions related to processing the images. In particular checkout the documentation for `skimage.io.imread_collection` and `skimage.transform.resize`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1JusVBB5lwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your path \n",
        "forests = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data/train/forest/*.jpg'\n",
        "mountains = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data/train/mountain/*.jpg'\n",
        "val_forests = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data/validation/forest/*.jpg'\n",
        "val_mountains = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data/validation/mountain/*.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrdxayxD5lzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a collection with the available images\n",
        "forests = imread_collection(forests).concatenate()\n",
        "mountains = imread_collection(mountains).concatenate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK68rG1gBswu",
        "colab_type": "code",
        "outputId": "47e723f1-f329-4cfe-e985-93af647ddfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "forests.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268, 256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SXgKE1_5l2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_0 =  np.zeros(forests.shape[0])\n",
        "y_1 =  np.ones(mountains.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4oj4jlU5l4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate([forests, mountains])\n",
        "X = resize(X, (520,256,256,3))\n",
        "y = np.concatenate([y_0, y_1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaTGo-K75l7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CZAFks05k3z",
        "colab_type": "code",
        "outputId": "3bdb5638-9689-40d0-98f7-3a0cb3a0098f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.69019608, 0.54509804, 0.43137255],\n",
              "         [0.74509804, 0.58823529, 0.49019608],\n",
              "         [0.79215686, 0.62745098, 0.53333333],\n",
              "         ...,\n",
              "         [0.8745098 , 0.56862745, 0.41960784],\n",
              "         [0.83529412, 0.52941176, 0.38823529],\n",
              "         [0.85490196, 0.54117647, 0.40392157]],\n",
              "\n",
              "        [[0.62745098, 0.4745098 , 0.35294118],\n",
              "         [0.73333333, 0.57254902, 0.4627451 ],\n",
              "         [0.78823529, 0.62352941, 0.5254902 ],\n",
              "         ...,\n",
              "         [0.84705882, 0.54117647, 0.39215686],\n",
              "         [0.83529412, 0.52941176, 0.38039216],\n",
              "         [0.83921569, 0.54509804, 0.39215686]],\n",
              "\n",
              "        [[0.66666667, 0.49803922, 0.37254902],\n",
              "         [0.68235294, 0.52156863, 0.41176471],\n",
              "         [0.80784314, 0.64313725, 0.54509804],\n",
              "         ...,\n",
              "         [0.8627451 , 0.54901961, 0.41176471],\n",
              "         [0.85882353, 0.55294118, 0.40392157],\n",
              "         [0.84313725, 0.54901961, 0.39215686]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.07843137, 0.30196078, 0.        ],\n",
              "         [0.16862745, 0.39215686, 0.08235294],\n",
              "         [0.25490196, 0.47843137, 0.16862745],\n",
              "         ...,\n",
              "         [0.26666667, 0.50980392, 0.17647059],\n",
              "         [0.22352941, 0.47843137, 0.11764706],\n",
              "         [0.25490196, 0.50588235, 0.1372549 ]],\n",
              "\n",
              "        [[0.05490196, 0.29411765, 0.        ],\n",
              "         [0.15686275, 0.39607843, 0.09019608],\n",
              "         [0.23529412, 0.4627451 , 0.16078431],\n",
              "         ...,\n",
              "         [0.2745098 , 0.50588235, 0.17647059],\n",
              "         [0.28627451, 0.52156863, 0.18431373],\n",
              "         [0.26666667, 0.50196078, 0.16470588]],\n",
              "\n",
              "        [[0.05882353, 0.30980392, 0.01176471],\n",
              "         [0.2       , 0.44313725, 0.14901961],\n",
              "         [0.23529412, 0.4627451 , 0.17254902],\n",
              "         ...,\n",
              "         [0.30980392, 0.5372549 , 0.20784314],\n",
              "         [0.29019608, 0.51372549, 0.19607843],\n",
              "         [0.27843137, 0.50980392, 0.19607843]]],\n",
              "\n",
              "\n",
              "       [[[0.44705882, 0.55294118, 0.61960784],\n",
              "         [0.38431373, 0.49019608, 0.56470588],\n",
              "         [0.32941176, 0.43529412, 0.51764706],\n",
              "         ...,\n",
              "         [0.21176471, 0.3254902 , 0.38823529],\n",
              "         [0.21176471, 0.31764706, 0.38431373],\n",
              "         [0.21176471, 0.31764706, 0.39215686]],\n",
              "\n",
              "        [[0.18431373, 0.28627451, 0.35294118],\n",
              "         [0.19607843, 0.30196078, 0.37647059],\n",
              "         [0.21568627, 0.32156863, 0.40392157],\n",
              "         ...,\n",
              "         [0.19607843, 0.30980392, 0.38039216],\n",
              "         [0.2       , 0.30588235, 0.38039216],\n",
              "         [0.20392157, 0.30980392, 0.38431373]],\n",
              "\n",
              "        [[0.23921569, 0.3372549 , 0.41568627],\n",
              "         [0.23529412, 0.33333333, 0.41960784],\n",
              "         [0.22745098, 0.33333333, 0.41568627],\n",
              "         ...,\n",
              "         [0.20392157, 0.31764706, 0.38823529],\n",
              "         [0.19607843, 0.30980392, 0.38039216],\n",
              "         [0.2       , 0.30588235, 0.38039216]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.01960784, 0.02745098, 0.01568627],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         ...,\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314]],\n",
              "\n",
              "        [[0.01568627, 0.02352941, 0.01176471],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         ...,\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314]],\n",
              "\n",
              "        [[0.01568627, 0.02352941, 0.01960784],\n",
              "         [0.01568627, 0.02352941, 0.01960784],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         ...,\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314],\n",
              "         [0.01960784, 0.02745098, 0.00784314]]],\n",
              "\n",
              "\n",
              "       [[[0.13333333, 0.20392157, 0.36078431],\n",
              "         [0.1372549 , 0.19607843, 0.35686275],\n",
              "         [0.13333333, 0.19215686, 0.35294118],\n",
              "         ...,\n",
              "         [0.16862745, 0.22352941, 0.36862745],\n",
              "         [0.18039216, 0.22745098, 0.37647059],\n",
              "         [0.18039216, 0.22745098, 0.38431373]],\n",
              "\n",
              "        [[0.13333333, 0.20392157, 0.36078431],\n",
              "         [0.14117647, 0.2       , 0.36078431],\n",
              "         [0.14509804, 0.19607843, 0.36078431],\n",
              "         ...,\n",
              "         [0.17254902, 0.22745098, 0.37254902],\n",
              "         [0.18039216, 0.22745098, 0.37647059],\n",
              "         [0.18431373, 0.23137255, 0.38823529]],\n",
              "\n",
              "        [[0.14117647, 0.2       , 0.36078431],\n",
              "         [0.14901961, 0.20784314, 0.36862745],\n",
              "         [0.15294118, 0.20392157, 0.36862745],\n",
              "         ...,\n",
              "         [0.17647059, 0.23137255, 0.37647059],\n",
              "         [0.18431373, 0.23137255, 0.38039216],\n",
              "         [0.18039216, 0.22745098, 0.38431373]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.89019608, 0.87058824, 0.94901961],\n",
              "         [0.89411765, 0.87843137, 0.96862745],\n",
              "         [0.89803922, 0.89803922, 0.99215686],\n",
              "         ...,\n",
              "         [0.90588235, 0.91372549, 0.99607843],\n",
              "         [0.93333333, 0.9372549 , 1.        ],\n",
              "         [0.9254902 , 0.92156863, 0.99215686]],\n",
              "\n",
              "        [[0.7254902 , 0.71372549, 0.78823529],\n",
              "         [0.73333333, 0.72941176, 0.8       ],\n",
              "         [0.70588235, 0.70980392, 0.78039216],\n",
              "         ...,\n",
              "         [0.74901961, 0.75686275, 0.81568627],\n",
              "         [0.77647059, 0.77254902, 0.83529412],\n",
              "         [0.75294118, 0.74901961, 0.81176471]],\n",
              "\n",
              "        [[0.09803922, 0.09411765, 0.16470588],\n",
              "         [0.13333333, 0.12941176, 0.19215686],\n",
              "         [0.11764706, 0.1254902 , 0.18431373],\n",
              "         ...,\n",
              "         [0.10588235, 0.10588235, 0.14509804],\n",
              "         [0.10588235, 0.09803922, 0.14901961],\n",
              "         [0.09411765, 0.08627451, 0.14117647]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.29803922, 0.4745098 , 0.54901961],\n",
              "         [0.29411765, 0.48235294, 0.56078431],\n",
              "         [0.28235294, 0.48235294, 0.54901961],\n",
              "         ...,\n",
              "         [0.75686275, 0.84705882, 0.78431373],\n",
              "         [0.75294118, 0.83529412, 0.77647059],\n",
              "         [0.70588235, 0.77647059, 0.71372549]],\n",
              "\n",
              "        [[0.28627451, 0.49019608, 0.54509804],\n",
              "         [0.28235294, 0.48235294, 0.54901961],\n",
              "         [0.28235294, 0.49019608, 0.55294118],\n",
              "         ...,\n",
              "         [0.7372549 , 0.82745098, 0.74901961],\n",
              "         [0.71764706, 0.80784314, 0.7372549 ],\n",
              "         [0.66666667, 0.74509804, 0.69803922]],\n",
              "\n",
              "        [[0.27058824, 0.47843137, 0.53333333],\n",
              "         [0.28235294, 0.48235294, 0.54901961],\n",
              "         [0.27843137, 0.47843137, 0.55294118],\n",
              "         ...,\n",
              "         [0.68627451, 0.78039216, 0.68627451],\n",
              "         [0.69411765, 0.78431373, 0.70588235],\n",
              "         [0.66666667, 0.75294118, 0.70196078]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.03137255, 0.11764706, 0.03529412],\n",
              "         [0.04313725, 0.13333333, 0.03137255],\n",
              "         [0.03529412, 0.13333333, 0.01960784],\n",
              "         ...,\n",
              "         [0.58039216, 0.65098039, 0.54901961],\n",
              "         [0.56470588, 0.62352941, 0.50980392],\n",
              "         [0.59607843, 0.63529412, 0.52941176]],\n",
              "\n",
              "        [[0.01568627, 0.10980392, 0.02352941],\n",
              "         [0.03529412, 0.12941176, 0.03529412],\n",
              "         [0.03529412, 0.12941176, 0.02745098],\n",
              "         ...,\n",
              "         [0.51372549, 0.56862745, 0.43921569],\n",
              "         [0.52941176, 0.56862745, 0.43529412],\n",
              "         [0.74117647, 0.76078431, 0.64313725]],\n",
              "\n",
              "        [[0.        , 0.09803922, 0.01176471],\n",
              "         [0.02745098, 0.1254902 , 0.03921569],\n",
              "         [0.03529412, 0.12941176, 0.03529412],\n",
              "         ...,\n",
              "         [0.69411765, 0.7254902 , 0.58039216],\n",
              "         [0.67058824, 0.68627451, 0.55686275],\n",
              "         [0.87843137, 0.8745098 , 0.75294118]]],\n",
              "\n",
              "\n",
              "       [[[0.21568627, 0.38431373, 0.56078431],\n",
              "         [0.21176471, 0.38039216, 0.55686275],\n",
              "         [0.20784314, 0.37647059, 0.55294118],\n",
              "         ...,\n",
              "         [0.18431373, 0.38431373, 0.55294118],\n",
              "         [0.18039216, 0.38823529, 0.54509804],\n",
              "         [0.17647059, 0.38431373, 0.54117647]],\n",
              "\n",
              "        [[0.21568627, 0.38431373, 0.56078431],\n",
              "         [0.21176471, 0.38039216, 0.55686275],\n",
              "         [0.20784314, 0.37647059, 0.55294118],\n",
              "         ...,\n",
              "         [0.18431373, 0.38431373, 0.55294118],\n",
              "         [0.18431373, 0.38431373, 0.55294118],\n",
              "         [0.18039216, 0.38431373, 0.54117647]],\n",
              "\n",
              "        [[0.21960784, 0.38823529, 0.56470588],\n",
              "         [0.21176471, 0.38039216, 0.55686275],\n",
              "         [0.20784314, 0.37647059, 0.55294118],\n",
              "         ...,\n",
              "         [0.18039216, 0.38039216, 0.54901961],\n",
              "         [0.18039216, 0.38039216, 0.54901961],\n",
              "         [0.18039216, 0.38431373, 0.54117647]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.11372549, 0.18823529, 0.24705882],\n",
              "         [0.11372549, 0.18823529, 0.24705882],\n",
              "         [0.11372549, 0.18823529, 0.24705882],\n",
              "         ...,\n",
              "         [0.55686275, 0.60392157, 0.60392157],\n",
              "         [0.55686275, 0.60392157, 0.60392157],\n",
              "         [0.55686275, 0.60392157, 0.60392157]],\n",
              "\n",
              "        [[0.11764706, 0.19215686, 0.25098039],\n",
              "         [0.11372549, 0.18823529, 0.24705882],\n",
              "         [0.11372549, 0.18823529, 0.24705882],\n",
              "         ...,\n",
              "         [0.55294118, 0.6       , 0.6       ],\n",
              "         [0.54901961, 0.59607843, 0.59607843],\n",
              "         [0.54901961, 0.59607843, 0.59607843]],\n",
              "\n",
              "        [[0.11764706, 0.19215686, 0.25098039],\n",
              "         [0.11764706, 0.19215686, 0.25098039],\n",
              "         [0.11764706, 0.19215686, 0.25098039],\n",
              "         ...,\n",
              "         [0.54901961, 0.59607843, 0.59607843],\n",
              "         [0.54509804, 0.59215686, 0.59215686],\n",
              "         [0.54509804, 0.59215686, 0.59215686]]],\n",
              "\n",
              "\n",
              "       [[[0.20392157, 0.21960784, 0.23137255],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         ...,\n",
              "         [0.46666667, 0.60784314, 0.85098039],\n",
              "         [0.46666667, 0.60784314, 0.85098039],\n",
              "         [0.47058824, 0.61176471, 0.85490196]],\n",
              "\n",
              "        [[0.2       , 0.21568627, 0.22745098],\n",
              "         [0.2       , 0.21568627, 0.22745098],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         ...,\n",
              "         [0.47058824, 0.61176471, 0.85490196],\n",
              "         [0.4627451 , 0.60392157, 0.84705882],\n",
              "         [0.46666667, 0.60784314, 0.85098039]],\n",
              "\n",
              "        [[0.19215686, 0.20784314, 0.21960784],\n",
              "         [0.19215686, 0.20784314, 0.21960784],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         ...,\n",
              "         [0.48627451, 0.62745098, 0.87058824],\n",
              "         [0.47843137, 0.61960784, 0.8627451 ],\n",
              "         [0.47843137, 0.61960784, 0.8627451 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20784314, 0.22352941, 0.23529412],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         [0.2       , 0.21568627, 0.22745098],\n",
              "         ...,\n",
              "         [0.25098039, 0.2745098 , 0.25882353],\n",
              "         [0.25098039, 0.2745098 , 0.25882353],\n",
              "         [0.20392157, 0.22745098, 0.21176471]],\n",
              "\n",
              "        [[0.20784314, 0.22352941, 0.23529412],\n",
              "         [0.20784314, 0.22352941, 0.23529412],\n",
              "         [0.20392157, 0.21960784, 0.23137255],\n",
              "         ...,\n",
              "         [0.24313725, 0.26666667, 0.25882353],\n",
              "         [0.27843137, 0.30196078, 0.29411765],\n",
              "         [0.27058824, 0.29411765, 0.29411765]],\n",
              "\n",
              "        [[0.20784314, 0.22352941, 0.23529412],\n",
              "         [0.20784314, 0.22352941, 0.23529412],\n",
              "         [0.21176471, 0.22745098, 0.23921569],\n",
              "         ...,\n",
              "         [0.24313725, 0.26666667, 0.25882353],\n",
              "         [0.25098039, 0.2745098 , 0.2745098 ],\n",
              "         [0.24313725, 0.25882353, 0.27058824]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A000pFEWrDzG",
        "colab_type": "text"
      },
      "source": [
        "## Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGCLJmTgF0_N",
        "colab_type": "code",
        "outputId": "bbccad08-8c87-4407-def3-3908b30df044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(260, 256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifowUhnTHRKO",
        "colab_type": "code",
        "outputId": "89d472c9-278a-4a8a-bcc8-57750e7c4969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Create the base model from the pre-trained model ResNet\n",
        "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape= (256,256,3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Wal7_FQKNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZaSktxNN9uU",
        "colab_type": "code",
        "outputId": "7c09a3bf-db74-45f2-a9b3-6a9e666ff5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvAZnqqzVS7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH  = '/content/drive/My Drive/Colab Notebooks/Unit 4 Sprint 3 Major NN Arch/data'\n",
        "IMAGE_SIZE    = (255, 255)\n",
        "NUM_CLASSES   = 2\n",
        "BATCH_SIZE    = 5  # try reducing batch size or freeze more layers if your GPU runs out of memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q31918o7VSz_",
        "colab_type": "code",
        "outputId": "bddc6734-8afa-46f1-8479-1903afc4bc90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_batches = train_data.flow_from_directory(DATASET_PATH + '/train',\n",
        "                                                  target_size=IMAGE_SIZE,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "\n",
        "\n",
        "valid_batches = valid_data.flow_from_directory(DATASET_PATH + '/validation',\n",
        "                                                  target_size=IMAGE_SIZE,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 520 images belonging to 2 classes.\n",
            "Found 182 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG2MtgsVZfnU",
        "colab_type": "code",
        "outputId": "8edaf14b-cb43-4864-ca41-61a11f19dfb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# show class indices\n",
        "print('****************')\n",
        "for cls, idx in train_batches.class_indices.items():\n",
        "    print('Class #{} = {}'.format(idx, cls))\n",
        "print('****************')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************\n",
            "Class #0 = forest\n",
            "Class #1 = mountain\n",
            "****************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nQPWYlVSuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xgRqhjRZE5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
        "network = Model(inputs=base_model.input, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LE7ZvquZTUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network.compile(optimizer=Adam(lr=0.001),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTKnL-lVaDaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.01, patience=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hlpNLnlZsRY",
        "colab_type": "code",
        "outputId": "5d902b84-eac6-4482-87cb-0b9e24db2e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "network.fit(\n",
        "        train_batches,\n",
        "        epochs=10,\n",
        "        validation_data=valid_batches,\n",
        "        verbose=1,\n",
        "        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
        "        callbacks=[stop],\n",
        "        validation_steps = valid_batches.samples // BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 140s 1s/step - loss: 3.0188 - accuracy: 0.7538 - val_loss: 2.8799 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 137s 1s/step - loss: 1.3443 - accuracy: 0.8500 - val_loss: 0.6967 - val_accuracy: 0.9167\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 135s 1s/step - loss: 0.8530 - accuracy: 0.9115 - val_loss: 3.7993 - val_accuracy: 0.7222\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 136s 1s/step - loss: 0.1349 - accuracy: 0.9827 - val_loss: 0.6439 - val_accuracy: 0.8944\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 136s 1s/step - loss: 0.0662 - accuracy: 0.9865 - val_loss: 1.4625 - val_accuracy: 0.8278\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1742e01ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTNqGVzPrDzN",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model\n",
        "\n",
        "In this step, write and train your own convolutional neural network using Keras. You can use any architecture that suits you as long as it has at least one convolutional and one pooling layer at the beginning of the network - you can add more if you want. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u2gmCwxrDzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVcDkH_yb2Xz",
        "colab_type": "code",
        "outputId": "0d7c93f3-3586-4f7c-f03f-e58de4eb3120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "# Setup Architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 125, 125, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 230400)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                14745664  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 14,802,049\n",
            "Trainable params: 14,802,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KFQ2Qccb2b3",
        "colab_type": "code",
        "outputId": "d2219605-e8c9-43bc-df5d-f16cc6ed0095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# Print summary\n",
        "model.fit(train_batches,\n",
        "          epochs=10,\n",
        "          validation_data=valid_batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-424b864bf613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_batches,\n\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=valid_batches)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Can not squeeze dim[1], expected a dimension of 1, got 2\n\t [[node Squeeze (defined at <ipython-input-19-424b864bf613>:3) ]] [Op:__inference_train_function_1983]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuyNft5siI-e",
        "colab_type": "code",
        "outputId": "aacae6d7-aeb0-420a-df1e-93bfebb0c5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Normalize from 0-1\n",
        "x_train = x_train.astype('float32') / 260.\n",
        "x_test = x_test.astype('float32') / 260.\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with the Tensorflow.Keras API\n",
        "#X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "#X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Setup Architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print summary\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "9/9 [==============================] - 28s 3s/step - loss: 1.3718 - accuracy: 0.4769 - val_loss: 0.8538 - val_accuracy: 0.5231\n",
            "Epoch 2/5\n",
            "9/9 [==============================] - 28s 3s/step - loss: 0.7843 - accuracy: 0.5154 - val_loss: 0.7391 - val_accuracy: 0.5231\n",
            "Epoch 3/5\n",
            "9/9 [==============================] - 28s 3s/step - loss: 0.7570 - accuracy: 0.5000 - val_loss: 0.7241 - val_accuracy: 0.4769\n",
            "Epoch 4/5\n",
            "9/9 [==============================] - 28s 3s/step - loss: 0.7040 - accuracy: 0.5231 - val_loss: 0.7331 - val_accuracy: 0.5231\n",
            "Epoch 5/5\n",
            "9/9 [==============================] - 28s 3s/step - loss: 0.7128 - accuracy: 0.5231 - val_loss: 0.7279 - val_accuracy: 0.4769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7888e2d780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkPjmGDDrDzV",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model with Image Manipulations\n",
        "## *This a stretch goal, and it's relatively difficult*\n",
        "\n",
        "To simulate an increase in a sample of image, you can apply image manipulation techniques: cropping, rotation, stretching, etc. Luckily Keras has some handy functions for us to apply these techniques to our mountain and forest example. Check out these resources to help you get started: \n",
        "\n",
        "1. [Keras `ImageGenerator` Class](https://keras.io/preprocessing/image/#imagedatagenerator-class)\n",
        "2. [Building a powerful image classifier with very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNnevVsqrDzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# State Code for Image Manipulation Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "Stretch goals\n",
        "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
        "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
        "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
        "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
        "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
        "\n",
        "Resources\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
        "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
        "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
        "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
        "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
      ]
    }
  ]
}